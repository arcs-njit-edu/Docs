Specification,10gb,20gb,40gb,Full 80GB,Notes
Device Name,A100 MIG 10gb,A100 MIG 20gb,A100 MIG 40gb,A100-SXM4-80GB,MIG slice size
SU Usage factor,2,4,8,16,Service units
Global Memory,10.2 GB,20.9 GB,42.4 GB,85.2 GB,Raw hardware memory
Usable Memory,~9.5 GB,~20 GB,~40 GB,~80 GB,Available for applications
Multiprocessors (SMs),14,28,42,108,Parallel compute units
Relative Compute Power,1x,2x,3x,7.7x,Performance scaling
Total Parallel Threads,28672,57344,86016,221184,SMs × threads/SMP
Memory Bus Width,640 bits,1280 bits,2560 bits,5120 bits,Memory bandwidth
Memory Bandwidth limits,~1.3 TB/s,~2.6 TB/s,~5.1 TB/s,~10.2 TB/s,"Theoretical peak Bandwidth (B/s)=Memory Clock (Hz)×Bus Width (bits)÷8"
L2 Cache Size,5 MB,10 MB,20 MB,41 MB,Fast memory cache
Async Engines,1,2,3,5,Concurrent operations
Max Threads per Block,1024,1024,1024,1024,CUDA block limit
Max Threads per SMP,2048,2048,2048,2048,Per multiprocessor
Memory Clock,1593 MHz,1593 MHz,1593 MHz,1593 MHz,Memory frequency
Clock Rate,1410 MHz,1410 MHz,1410 MHz,1410 MHz,GPU core frequency
Shared Memory/Block,49 KB,49 KB,49 KB,49 KB,Per CUDA block
Registers per Block,65536,65536,65536,65536,Per CUDA block
Constant Memory,64 KB,64 KB,64 KB,64 KB,Read-only memory
Warp Size,32,32,32,32,SIMD execution width
ECC Support,Yes,Yes,Yes,Yes,Error correction
Unified Memory,Yes,Yes,Yes,Yes,CPU-GPU memory sharing
Concurrent Kernels,Yes,Yes,Yes,Yes,Multiple kernel execution
Max Grid Dimensions,2³¹-1 × 65535 × 65535,2³¹-1 × 65535 × 65535,2³¹-1 × 65535 × 65535,2³¹-1 × 65535 × 65535,CUDA grid limits